# -*- coding: utf-8 -*-
"""TFIDF Case Study.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VzQOBYsaIpRC6u10afJEAm3Rwl0-lPle
"""

# Install necessary libraries
!pip install --upgrade datasets scikit-learn

# Import libraries
from datasets import load_dataset
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# 1. Load the SMS Spam dataset
dataset = load_dataset("sms_spam")
texts = dataset['train']['sms']
labels = dataset['train']['label']

print(f"Total messages: {len(texts)}")
print(f"Class distribution: {np.bincount(labels)} (ham=0, spam=1)")

# 2. Split dataset into training and testing sets (80%-20%)
X_train, X_test, y_train, y_test = train_test_split(
    texts, labels, test_size=0.2, random_state=42, stratify=labels
)

# 3. Initialize TF-IDF Vectorizer
tfidf = TfidfVectorizer(stop_words='english', max_df=0.95, min_df=2)

# 4. Fit TF-IDF on training data and transform both train/test data
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)
print(f"Number of features (unique words): {X_train_tfidf.shape[1]}")

# 5. Train Logistic Regression classifier
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train_tfidf, y_train)

# 6. Predict on test data
y_pred = clf.predict(X_test_tfidf)

#7. Evaluation metrics

# Accuracy
acc = accuracy_score(y_test, y_pred)
print(f"Accuracy: {acc:.4f}")

# Detailed classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# 8. Optional: Extract top TF-IDF terms for each class

def top_tfidf_terms(vectorizer, clf, n=10):
    feature_names = np.array(vectorizer.get_feature_names_out())
    # Coefficients for each feature in Logistic Regression
    coefs = clf.coef_[0]
    top_positive_indices = np.argsort(coefs)[-n:]
    top_negative_indices = np.argsort(coefs)[:n]

    print(f"Top {n} words indicative of Spam:")
    print(feature_names[top_positive_indices][::-1])
    print(f"\nTop {n} words indicative of Ham:")
    print(feature_names[top_negative_indices])

top_tfidf_terms(tfidf, clf)

"""2 case study worst case"""

!pip install --upgrade datasets scikit-learn

from datasets import load_dataset
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load IMDb dataset
dataset = load_dataset("imdb")

# Take a small subset of 300 samples (balanced classes)
texts_pos = dataset['train'].filter(lambda x: x['label'] == 1).select(range(150))['text']
texts_neg = dataset['train'].filter(lambda x: x['label'] == 0).select(range(150))['text']

texts = texts_pos + texts_neg
labels = [1]*150 + [0]*150

print(f"Total samples: {len(texts)}")

# Split train-test 80-20
X_train, X_test, y_train, y_test = train_test_split(
    texts, labels, test_size=0.2, random_state=42, stratify=labels
)

# TF-IDF Vectorizer
tfidf = TfidfVectorizer(stop_words='english', max_df=0.95, min_df=2)
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

# Logistic Regression
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train_tfidf, y_train)
y_pred = clf.predict(X_test_tfidf)

#Evaluation
acc = accuracy_score(y_test, y_pred)
print(f"Accuracy: {acc:.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""3
 1. Data Preprocessing
"""

from datasets import load_dataset
import pandas as pd
import re

# Load Yelp Polarity dataset (subset)
dataset = load_dataset("yelp_polarity", split="train[:500]")
texts = dataset['text']
labels = dataset['label']  # 0 = negative, 1 = positive

# Cleaning function (basic)
def clean_text(text):
    text = re.sub(r'[^\w\s]', '', text.lower())  # Remove punctuation and lowercase
    text = re.sub(r'\d+', '', text)              # Remove numbers
    return text

texts_cleaned = [clean_text(t) for t in texts]

""" 2. TF-IDF Computation & Model Implementation"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    texts_cleaned, labels, test_size=0.2, random_state=42, stratify=labels
)

# TF-IDF Vectorizer
tfidf = TfidfVectorizer(stop_words='english', max_df=0.9, min_df=2, ngram_range=(1,2))
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

# Logistic Regression
model = LogisticRegression(max_iter=1000)
model.fit(X_train_tfidf, y_train)

# Predictions
y_pred = model.predict(X_test_tfidf)

""" 3. Evaluation Metrics"""

print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=["Negative", "Positive"]))

from sklearn.metrics.pairwise import cosine_similarity

# Get similarity between 2 random reviews
similarity = cosine_similarity(X_test_tfidf[0], X_test_tfidf[1])
print(f"Similarity between doc 1 & 2: {similarity[0][0]:.4f}")

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Create display object
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])

# Plot using matplotlib
fig, ax = plt.subplots(figsize=(6, 5))
disp.plot(ax=ax, cmap=plt.cm.Blues)
plt.title("Confusion Matrix - Yelp Polarity (TF-IDF + Logistic Regression)")
plt.show()



import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

model_metrics_named = [{
    "model": "Logistic Regression (SMS Spam)",
    "accuracy": 0.9785,
    "precision": 1.0,
    "recall": 0.84,
    "f1_score": 0.91
}]

model_metrics_named.append({
    "model": "Logistic Regression (IMDb Subset)",
    "accuracy": 0.9333,
})

model_metrics_named.append({
    "model": "Logistic Regression (Yelp Polarity Subset)",
    "accuracy": 0.72,
})


labels = [m["model"] for m in model_metrics_named]
accuracies = [m["accuracy"] for m in model_metrics_named]

plt.figure(figsize=(8, 8))
plt.pie(accuracies, labels=labels, autopct='%1.2f%%', startangle=140)
plt.title("Model Accuracy Comparison Across Datasets (Pie Chart)\n")
plt.axis('equal')
plt.show()


df_metrics = pd.DataFrame(model_metrics_named)
print("\nMetrics used for the pie chart:")
print(df_metrics[['model', 'accuracy']])

# --- Create Bar Graph ---
plt.figure(figsize=(10, 6))
sns.barplot(x=labels, y=accuracies, palette='viridis')
plt.ylabel('Accuracy')
plt.title('Model Accuracy Comparison Across Datasets (Bar Graph)')
plt.ylim(0, 1.1)
plt.xticks(rotation=15, ha='right')
plt.tight_layout()
plt.show()



df_metrics = pd.DataFrame(model_metrics_named)
print("\nMetrics used for the plots:")
print(df_metrics[['model', 'accuracy']]) # Only show th

